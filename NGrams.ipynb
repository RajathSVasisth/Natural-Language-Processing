{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To execute the code:\n",
        "* Click Run on each cell sequentially or select the Run All Option.\n",
        "* To know what each cell does, please read the comment on the header."
      ],
      "metadata": {
        "id": "7AFUJDxipOUL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ6sEcsSLqzy",
        "outputId": "c3ddddd6-67bc-4524-d851-4492fc608e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"brown\")\n",
        "nltk.download(\"webtext\")\n",
        "nltk.download(\"reuters\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "from collections import Counter\n",
        "from nltk.corpus import brown, webtext, reuters\n",
        "brown_corpus = brown.sents()\n",
        "brown_corpus = [\" \".join(sentence) for sentence in brown_corpus]\n",
        "brown_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in brown_corpus][:5000]\n",
        "webtext_corpus = webtext.sents()\n",
        "webtext_corpus = [\" \".join(sentence) for sentence in webtext_corpus]\n",
        "webtext_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in webtext_corpus][:5000]\n",
        "reuters_corpus = reuters.sents()\n",
        "reuters_corpus = [\" \".join(sentence) for sentence in reuters_corpus]\n",
        "reuters_corpus = [\"<s> \" + sentence + \" </s>\" for sentence in reuters_corpus][:5000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Arrange sentences as array of tuple values for any n = 1,2,3\n",
        "\n",
        "def get_ngrams(corpus, n):\n",
        "    ngrams = []\n",
        "    for sentence in corpus:\n",
        "        tokens = sentence.split()\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            if n == 1:\n",
        "                ngram = tokens[i]\n",
        "            else:\n",
        "              ngram = tuple(tokens[i:i+n])\n",
        "            ngrams.append(ngram)\n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "17ObOOKaMpl3"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate unigram, bigram and trigram tuples for both Brown and Webtext datasets\n",
        "brown_unigrams = get_ngrams(brown_corpus, 1)\n",
        "brown_bigrams = get_ngrams(brown_corpus, 2)\n",
        "brown_trigrams = get_ngrams(brown_corpus, 3)\n",
        "\n",
        "webtext_unigrams = get_ngrams(webtext_corpus, 1)\n",
        "webtext_bigrams = get_ngrams(webtext_corpus, 2)\n",
        "webtext_trigrams = get_ngrams(webtext_corpus, 3)\n",
        "\n",
        "# Generate the counter object for each gram of both datasets\n",
        "count_brown_unigrams = Counter(brown_unigrams)\n",
        "count_brown_bigrams = Counter(brown_bigrams)\n",
        "count_brown_trigrams = Counter(brown_trigrams)\n",
        "\n",
        "count_webtext_unigrams = Counter(webtext_unigrams)\n",
        "count_webtext_bigrams = Counter(webtext_bigrams)\n",
        "count_webtext_trigrams = Counter(webtext_trigrams)"
      ],
      "metadata": {
        "id": "sm6Limp7g6UN"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions for unigram, bigram and trigram probablities\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def unigram_probability(word, count_unigrams):\n",
        "    if word in count_unigrams:\n",
        "        return count_unigrams[word] / len(brown_unigrams)\n",
        "    else:\n",
        "        return np.nextafter(0,1)\n",
        "\n",
        "def bigram_probability(word1, word2, count_unigrams, count_bigrams):\n",
        "    if (word1, word2) in count_bigrams:\n",
        "        return (count_bigrams[(word1, word2)] + 1) / (count_unigrams[word1] + len(count_unigrams))\n",
        "    else:\n",
        "        return 1 / (count_unigrams[word1] + len(count_unigrams))\n",
        "\n",
        "def trigram_probability(word1, word2, word3, count_unigrams, count_bigrams, count_trigrams):\n",
        "  if (word1, word2, word3) in count_trigrams:\n",
        "    return (count_trigrams[(word1, word2, word3)] + 1) / (count_bigrams[(word1, word2)] + len(count_unigrams))\n",
        "  else:\n",
        "    return 1 / (count_bigrams[(word1, word2)] + len(count_unigrams))"
      ],
      "metadata": {
        "id": "linOE3-XhMaM"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to predict next word suing bigram/trigram using highest probablity measure\n",
        "\n",
        "def bigram_next_word(word, count_unigrams, count_bigrams):\n",
        "    next_word = None\n",
        "    max_prob = 0\n",
        "    for w in count_unigrams:\n",
        "        prob = bigram_probability(word, w, count_unigrams, count_bigrams)\n",
        "        if prob > max_prob:\n",
        "            max_prob = prob\n",
        "            next_word = w\n",
        "    return next_word\n",
        "\n",
        "def trigram_next_word(word1, word2, count_unigrams, count_bigrams, count_trigrams):\n",
        "    next_word = None\n",
        "    max_prob = 0\n",
        "    for w in count_unigrams:\n",
        "        prob = trigram_probability(word1, word2, w, count_unigrams, count_bigrams, count_trigrams)\n",
        "        if prob > max_prob:\n",
        "            max_prob = prob\n",
        "            next_word = w\n",
        "    return next_word"
      ],
      "metadata": {
        "id": "74uFWcj-h0Fu"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to generate next words until a fixed length given an inital sequence using bigram/trigram models\n",
        "\n",
        "import re\n",
        "\n",
        "def generate_sentence_bigram(given_seq, count_unigrams, count_bigrams):\n",
        "    sentence = given_seq.split()\n",
        "    while True:\n",
        "        if len(sentence) == 10:\n",
        "            break\n",
        "        sentence.append(bigram_next_word(sentence[-1], count_unigrams, count_bigrams))\n",
        "\n",
        "        pattern = r\"</s>\"\n",
        "        if re.search(pattern, sentence[-1]):\n",
        "            break\n",
        "\n",
        "    return \" \".join(sentence)\n",
        "\n",
        "def generate_sentence_trigram(given_seq, count_unigrams, count_bigrams, count_trigrams):\n",
        "    sentence = given_seq.split()\n",
        "    while True:\n",
        "        if len(sentence) == 10:\n",
        "            break\n",
        "        sentence.append(trigram_next_word(sentence[-2], sentence[-1], count_unigrams, count_bigrams, count_trigrams))\n",
        "\n",
        "        pattern = r\"</s>\"\n",
        "        if re.search(pattern, sentence[-1]):\n",
        "            break\n",
        "\n",
        "    return \" \".join(sentence)"
      ],
      "metadata": {
        "id": "YsZ45kf6tEvR"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to calculate unigram, bigram, trigram perplexities for given sentence and corpus count object\n",
        "\n",
        "def perplexity_ug(given_sentence, count_unigrams):\n",
        "    sentence = given_sentence.split()\n",
        "    mul_prob = None\n",
        "    for word in sentence:\n",
        "        if mul_prob is None:\n",
        "            mul_prob = unigram_probability(word, count_unigrams)\n",
        "        else:\n",
        "            mul_prob *= unigram_probability(word, count_unigrams)\n",
        "    return pow(1 / mul_prob, 1 / len(sentence))\n",
        "\n",
        "def perplexity_bg(given_sentence, count_unigrams, count_bigrams):\n",
        "    sentence = given_sentence.split()\n",
        "    mul_prob = None\n",
        "    for i in range(len(sentence)):\n",
        "        if i == 0:\n",
        "            mul_prob = unigram_probability(sentence[i], count_unigrams)\n",
        "        else:\n",
        "            mul_prob *= bigram_probability(sentence[i-1], sentence[i], count_unigrams, count_bigrams)\n",
        "    return pow(1 / mul_prob, 1 / len(sentence))\n",
        "\n",
        "def perplexity_tg(given_sentence, count_unigrams, count_bigrams, count_trigrams):\n",
        "    sentence = given_sentence.split()\n",
        "    mul_prob = None\n",
        "    for i in range(len(sentence)):\n",
        "        if i==0:\n",
        "            mul_prob = unigram_probability(sentence[i], count_unigrams)\n",
        "        elif i==1:\n",
        "            mul_prob *= bigram_probability(sentence[i-1], sentence[i], count_unigrams, count_bigrams)\n",
        "        else:\n",
        "            mul_prob *= trigram_probability(sentence[i-2], sentence[i-1], sentence[i], count_unigrams, count_bigrams, count_trigrams)\n",
        "    return pow(1 / mul_prob, 1 / len(sentence))"
      ],
      "metadata": {
        "id": "tQnNQfbC1iw1"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wrtten Report Question 1: (a) Which one (bigram/trigram) generates more coherent text on brown corpus training?\n",
        "\n",
        "print(\"Bigram vs Trigram: Generation\")\n",
        "print(\"\\nSentence 1: \\n\")\n",
        "print(generate_sentence_bigram(\"<s> I\", count_brown_unigrams, count_brown_bigrams))\n",
        "print(generate_sentence_trigram(\"<s> I\", count_brown_unigrams, count_brown_bigrams, count_brown_trigrams))\n",
        "\n",
        "print(\"\\nSentence 2: \\n\")\n",
        "print(generate_sentence_bigram(\"<s> Is\", count_brown_unigrams, count_brown_bigrams))\n",
        "print(generate_sentence_trigram(\"<s> Is\", count_brown_unigrams, count_brown_bigrams, count_brown_trigrams))\n",
        "\n",
        "print(\"\\nSentence 3: \\n\")\n",
        "print(generate_sentence_bigram(\"<s> The\", count_brown_unigrams, count_brown_bigrams))\n",
        "print(generate_sentence_trigram(\"<s> The\", count_brown_unigrams, count_brown_bigrams, count_brown_trigrams))\n",
        "\n",
        "print(\"\\nSentence 4: \\n\")\n",
        "print(generate_sentence_bigram(\"<s> He\", count_brown_unigrams, count_brown_bigrams))\n",
        "print(generate_sentence_trigram(\"<s> He\", count_brown_unigrams, count_brown_bigrams, count_brown_trigrams))\n",
        "\n",
        "print(\"\\nSentence 5: \\n\")\n",
        "print(generate_sentence_bigram(\"<s> There\", count_brown_unigrams, count_brown_bigrams))\n",
        "print(generate_sentence_trigram(\"<s> There\", count_brown_unigrams, count_brown_bigrams, count_brown_trigrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYTMfwNd3cgk",
        "outputId": "2c040b11-99ba-4272-b440-8001d3997129"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram vs Trigram: Generation\n",
            "\n",
            "Sentence 1: \n",
            "\n",
            "<s> I think you can be a year . </s>\n",
            "<s> I had to be a `` very serious misuse\n",
            "\n",
            "Sentence 2: \n",
            "\n",
            "<s> Is there is a year . </s>\n",
            "<s> Is there anything a frustrated individual can do .\n",
            "\n",
            "Sentence 3: \n",
            "\n",
            "<s> The President Kennedy , and the first time .\n",
            "<s> The President said he was the first time .\n",
            "\n",
            "Sentence 4: \n",
            "\n",
            "<s> He was a year . </s>\n",
            "<s> He was a member of the American League in\n",
            "\n",
            "Sentence 5: \n",
            "\n",
            "<s> There is a year . </s>\n",
            "<s> There are , in the past , the President\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Written Report Question 1: (b) Perplexity of Bigram Brown vs Trigram Brown for sentences from brown corpus\n",
        "\n",
        "import random\n",
        "\n",
        "random_numbers = random.sample(range(0, 4999), 5)\n",
        "print(\"Bigram vs Trigram: Perplexity\")\n",
        "\n",
        "for i in random_numbers:\n",
        "  print(\"\\n\" + brown_corpus[i] + \"\\n\")\n",
        "  print(\"Bigram: \", perplexity_bg(brown_corpus[i], count_brown_unigrams, count_brown_bigrams))\n",
        "  print(\"Trigram: \", perplexity_tg(brown_corpus[i], count_brown_unigrams, count_brown_bigrams, count_brown_trigrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dQ1hH5hCWK4",
        "outputId": "27a21e8c-b02f-4965-e56e-937b0410b45b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram vs Trigram: Perplexity\n",
            "\n",
            "<s> Every person will choose his own doctor and hospital '' . </s>\n",
            "\n",
            "Bigram:  1562.5061918227739\n",
            "Trigram:  3191.1927483435757\n",
            "\n",
            "<s> Student Prince Lounge on Atlantic Blvd. plotting a month-long `` festival '' throughout October , with special features . </s>\n",
            "\n",
            "Bigram:  3384.9242246130116\n",
            "Trigram:  5624.739906870103\n",
            "\n",
            "<s> Chief aims of the proposed conference are worth noting . </s>\n",
            "\n",
            "Bigram:  1497.9255719495868\n",
            "Trigram:  4803.58888277688\n",
            "\n",
            "<s> the junction of the Northeast and Northwest Expressways and Jones Avenue and Marietta Street , Aj . </s>\n",
            "\n",
            "Bigram:  2065.113288417077\n",
            "Trigram:  4398.251850844783\n",
            "\n",
            "<s> I visited the bank in March and wrote a story about the situation . </s>\n",
            "\n",
            "Bigram:  1819.9615035719285\n",
            "Trigram:  4083.525086740174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Written Report Question 2: Bigram Brown vs Bigram Webtext: Perplexity measure for 25 sentences from Reuters corpus\n",
        "\n",
        "random_numbers = random.sample(range(0, 4999), 25)\n",
        "print(\"Bigram Brown vs Bigram Webtext: Perplexity on Reuters\")\n",
        "brown_sum, webtext_sum = 0, 0\n",
        "\n",
        "for i in random_numbers:\n",
        "  print(\"\\n\" + reuters_corpus[i] + \"\\n\")\n",
        "  brown = perplexity_bg(reuters_corpus[i], count_brown_unigrams, count_brown_bigrams)\n",
        "  webtext = perplexity_bg(reuters_corpus[i], count_webtext_unigrams, count_webtext_bigrams)\n",
        "  print(\"Brown: \", brown)\n",
        "  print(\"Webtext: \", webtext)\n",
        "  brown_sum += brown\n",
        "  webtext_sum += webtext\n",
        "\n",
        "print(\"\\nBrown Avg Perplexity: \", brown_sum/25)\n",
        "print(\"Webtext Avg Perplexity : \", webtext_sum/25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-RhinNGD9jZ",
        "outputId": "8943b8a1-301d-406c-e8ed-f27079ed691c"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Brown vs Bigram Webtext: Perplexity on Reuters\n",
            "\n",
            "<s> No confirmation or further details were immediately available . </s>\n",
            "\n",
            "Brown:  3141.815851221653\n",
            "Webtext:  2092.666071560057\n",
            "\n",
            "<s> O ' SULLIVAN CORP & lt ; OSL > 1ST QTR NET Shr 28 cts vs 32 cts Net 2 , 823 , 000 vs 3 , 216 , 000 Rev 47 . 9 mln vs 42 . 9 mln NOTE : The 1986 earnings per share adjusted for a four for three stock distribution paid May 1986 . </s>\n",
            "\n",
            "Brown:  10001.296432106814\n",
            "Webtext:  6891.745103633949\n",
            "\n",
            "<s> The purchases of U . S . wheat completes the Export Enhancement Program initiative announced on December 31 , 1986 . </s>\n",
            "\n",
            "Brown:  5790.345476745267\n",
            "Webtext:  5302.51149118862\n",
            "\n",
            "<s> Stoltenberg said the Louvre agreement was working despite a \" slight firming \" of the yen against the dollar . </s>\n",
            "\n",
            "Brown:  3939.1698963760423\n",
            "Webtext:  3957.0988040268944\n",
            "\n",
            "<s> An additional 150 , 000 tonnes of wheat flour is still available to Iraq under the Export Enhancement Program initiative announced January 7 , 1987 , the department said . </s>\n",
            "\n",
            "Brown:  5175.73759900656\n",
            "Webtext:  5563.845476270052\n",
            "\n",
            "<s> C . O . M . B . & lt ; CMCO > MAKES ACQUISITION C . O . M . B . Co said it acquired for 8 . 7 mln dlrs the principal assets of National Tech Industries Inc and Telkon Corp . </s>\n",
            "\n",
            "Brown:  10652.479781158996\n",
            "Webtext:  7494.779452701412\n",
            "\n",
            "<s> ( 2 . 40 uncorrected .) </s>\n",
            "\n",
            "Brown:  3537.4449488617074\n",
            "Webtext:  1928.9200795632817\n",
            "\n",
            "<s> \" What has been happening is an important shift in the economy which makes the ministry a very important place ,\" said James Abegglen , head of the consulting firm Asia Advisory Service Inc . A decision to open the telecommunications industry to competition under a new set of laws passed in 1985 has boosted rather than lessened MPT ' s authority , analysts said . </s>\n",
            "\n",
            "Brown:  5873.08341055009\n",
            "Webtext:  4930.684147473235\n",
            "\n",
            "<s> It said four directors other than Cohen have resigned from the board . </s>\n",
            "\n",
            "Brown:  1989.397086844197\n",
            "Webtext:  2334.536152276552\n",
            "\n",
            "<s> However , orange production in the region for marketing year 1986 / 87 is forecast at 565 , 000 tonnes or 25 pct of the total Italian orange crop , it said . </s>\n",
            "\n",
            "Brown:  4378.684598817364\n",
            "Webtext:  4866.848231129955\n",
            "\n",
            "<s> \" I think the markets believe , and have believed for a long time , that the only recourse is to reflate at some point . </s>\n",
            "\n",
            "Brown:  2318.9327751456203\n",
            "Webtext:  2184.1090614257187\n",
            "\n",
            "<s> \" But there are more positives than negatives ,\" she said , citing reduced capacity in the domestic industry , better prices , and a weaker dollar , which should cause steel imports to drop off slightly from last year . </s>\n",
            "\n",
            "Brown:  4275.964683461774\n",
            "Webtext:  4764.705936752413\n",
            "\n",
            "<s> Currency dealers here and in the Far East said the dollar gained slight background support from the speculation . </s>\n",
            "\n",
            "Brown:  3285.2395806040468\n",
            "Webtext:  3088.6388609580013\n",
            "\n",
            "<s> GTE CORP 1ST QTR SHR 78 CTS VS 86 CTS </s>\n",
            "\n",
            "Brown:  9023.228994000505\n",
            "Webtext:  7013.102825528605\n",
            "\n",
            "<s> In last year ' s first quarter the company lost 60 . 0 mln dlrs or 55 cts per share on 108 . 4 mln shares outstanding , after a 110 . 8 mln dlr writedown of oil reserves of its Celeron Corp unit . </s>\n",
            "\n",
            "Brown:  7417.139431708914\n",
            "Webtext:  5354.8726206640995\n",
            "\n",
            "<s> Nobody so far said may would be closed ,\" he told Reuters . </s>\n",
            "\n",
            "Brown:  3043.1710964765844\n",
            "Webtext:  2907.9502720429477\n",
            "\n",
            "<s> Product futures , which fell sharply yesterday , are due to open unchanged to 0 . 25 cent lower , traders said . </s>\n",
            "\n",
            "Brown:  4551.772279897022\n",
            "Webtext:  2976.5746313008917\n",
            "\n",
            "<s> Attaka in Singapore is valued at 18 . 55 dlrs , a decline of 68 cts a barrel or 3 . 5 pct from the previous week . </s>\n",
            "\n",
            "Brown:  5204.4614550803135\n",
            "Webtext:  4374.834912384152\n",
            "\n",
            "<s> They said they believed the tonnage would be around 60 , 000 but declined to give a rebate figure . </s>\n",
            "\n",
            "Brown:  3791.1929794806583\n",
            "Webtext:  4206.494872807712\n",
            "\n",
            "<s> The company said 1986 dividend , which will be paid to the Dutch state in its capacity of the firm ' s sole shareholder , would be raised to 98 mln guilders from 70 mln guilders in 1985 . </s>\n",
            "\n",
            "Brown:  3256.3402443779805\n",
            "Webtext:  3953.0070092337114\n",
            "\n",
            "<s> Currency fluctuations reduced pretax profit by around one mln stg , it noted . </s>\n",
            "\n",
            "Brown:  4468.609239542692\n",
            "Webtext:  3902.103788328603\n",
            "\n",
            "<s> But Poehl said West Germany now faced a difficult dilemma over monetary policy . </s>\n",
            "\n",
            "Brown:  2886.409150232019\n",
            "Webtext:  4148.663259868583\n",
            "\n",
            "<s> Holders who wish to participate in the offer must first convert their preferred stock into Borg - Warner common stock . </s>\n",
            "\n",
            "Brown:  5383.377866184323\n",
            "Webtext:  4936.117819774923\n",
            "\n",
            "<s> \" However , the rate of this growth can be affected positively or negatively through government action or inaction ,\" Lichtblau said . </s>\n",
            "\n",
            "Brown:  3749.112200650555\n",
            "Webtext:  4237.747657217485\n",
            "\n",
            "<s> YUGOSLAV ECONOMY WORSENED IN 1986 , BANK DATA SHOWS National Bank economic data for 1986 shows that Yugoslavia ' s trade deficit grew , the inflation rate rose , wages were sharply higher , the money supply expanded and the value of the dinar fell . </s>\n",
            "\n",
            "Brown:  5943.017775899064\n",
            "Webtext:  5414.751821505193\n",
            "\n",
            "Brown Avg Perplexity:  4923.096993377231\n",
            "Webtext Avg Perplexity :  4353.092414384681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5FDbj6JYMVcq"
      }
    }
  ]
}